# Adapter-Hub adapter entry
# Defines a single adapter entry in Adapter-Hub
# --------------------

# The type of adapter (one of the options available in `adapter_type`.
type: text_task

# The string identifier of the task this adapter belongs to.
task: nli

# The string identifier of the subtask this adapter belongs to.
subtask: multinli

# The model type.
# Example: bert
model_type: bert

# The string identifier of the pre-trained model (by which it is identified at Huggingface).
# Example: bert-base-uncased
model_name: bert-base-multilingual-cased

# The name of the author(s) of this adapter.
author: Kabir Ahuja

# Describes the adapter architecture used by this adapter
config:
  # The name of the adapter config used by this adapter (a short name available in the `architectures` folder).
  # Example: pfeiffer
  using: pfeiffer
  non_linearity: relu
  reduction_factor: 2.0
default_version: '1'

# A list of different versions of this adapter available for download.
files:
- version: '1'
  sha1: 007cade7ced13ca4cbe2671ae07b273bf6eac522
  sha256: f836575380fb05d1fb691e501751cd83eb333258a241b3983b5459ec87728a65
  url: "https://dl.dropboxusercontent.com/s/t9opqk2m36cnau3/bert-base-multilingual-cased_nli_MultiNLI_adapter_config.json.zip"
citation: |
  @inproceedings{pfeiffer20madx,
    title = "{MAD-X}: {A}n {A}dapter-{B}ased {F}ramework for {M}ulti-{T}ask {C}ross-{L}ingual {T}ransfer",
    author = "Pfeiffer, Jonas  and
      Vuli{\'c}, Ivan  and
      Gurevych, Iryna  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.617",
    pages = "7654--7673",
  }
# (optional) A list of adapters this adapter is dependent on.
dependencies:
    # The key (username/filename_without_ext) of the adapter dependency.
    # Example: example-org/text_task-sst-bert
- key: 'en/wiki@ukp'
    # (optional) A short description how this adapter is dependent.
  description: 'Pfeiffer Adapter trained with Masked Language Modelling on English Wikipedia Articles for 250k steps and a batch size of 64.'
#   - ...

# (optional) A short description of this adapter.
description: 'Pfeiffer adapter stacked on top of language adapter for the NLI task. Trained on the English MultiNLI data for 10 epochs and a batch size of 64. Prediction head included. Important: Although, dependencies mention en/wiki@ukp, the adapter can be used with other language adapters as well like zh/wiki@ukp, de/wiki@ukp etc.'

# (optional) A contact email of the author(s).
email: kabirahuja2431@gmail.com

# (optional) A GitHub handle associated with the author(s).
github: https://github.com/kabirahuja2431

# (optional) The name of the model class from which this adapter was extracted. This field is mainly intended for adapters with prediction heads.
# Example: BertModelWithHeads
model_class: BertModel

# (optional) If the adapter has a pre-trained prediction head included.
prediction_head: true

# (optional) A Twitter handle associated with the author(s).
twitter: https://twitter.com/kabirahuja004

# (optional) A URL providing more information on this adapter/ the authors/ the organization.
url: https://kabirahuja2431.github.io/
